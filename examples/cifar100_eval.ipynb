{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbbe4b8-3584-48b6-8fad-4314f154c571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/PyInit_conv2d_mul8s_acc/build.ninja...\n",
      "Building extension module PyInit_conv2d_mul8s_acc...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_acc, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_acc...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "\n",
    "import requests\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.datasets import CIFAR100\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "#Step 1: Select models to load\n",
    "#####################################################################\n",
    "from models.resnet import resnet18, resnet34, resnet50\n",
    "from models.resnetcifar100 import resnet18cifar100\n",
    "from models.vgg import vgg11_bn, vgg13_bn, vgg19_bn\n",
    "from models.densenet import densenet121, densenet161, densenet169\n",
    "from models.inception import inception_v3 # slow, propably bad cifar10 implementation of inception for PT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Step 2: Select number of threads to use\n",
    "#####################################################################\n",
    "threads = 40\n",
    "torch.set_num_threads(threads)\n",
    "\n",
    "#maybe better performance\n",
    "os.environ['OMP_PLACES'] = 'cores'\n",
    "os.environ['OMP_PROC_BIND'] = 'close'\n",
    "os.environ['OMP_WAIT_POLICY'] = 'active'\n",
    "\n",
    "\n",
    "\n",
    "#Step 3: Choose approximate multiplier\n",
    "######################################################################\n",
    "axx_mult = 'mul8s_acc'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Step 4: Loading the ResNet18 Network for evaluation\n",
    "#######################################################################\n",
    "model = resnet18cifar100(pretrained=True, axx_mult = axx_mult)\n",
    "\n",
    "model.eval() # for evaluation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Load dataset\n",
    "######################################################################\n",
    "def val_dataloader(mean = (0.5071, 0.4867, 0.4408), std = (0.2675, 0.2565, 0.2761)):\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    dataset = CIFAR100(root=\"datasets/cifar100_data\", train=False, download=True, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "transform = T.Compose(\n",
    "        [\n",
    "            #T.RandomCrop(32, padding=4),\n",
    "            #T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean = (0.5071, 0.4867, 0.4408), std = (0.2675, 0.2565, 0.2761)),\n",
    "        ]\n",
    "    )\n",
    "dataset = CIFAR100(root=\"datasets/cifar100_data\", train=True, download=True, transform=transform)\n",
    "\n",
    "#evens = list(range(0, len(dataset), 100))\n",
    "#trainset_1 = torch.utils.data.Subset(dataset, evens)\n",
    "trainset_1 = dataset\n",
    "data = val_dataloader()\n",
    "\n",
    "# data_t is used for calibration purposes and is a subset of train-set\n",
    "data_t = DataLoader(trainset_1, batch_size=4096,\n",
    "                                            shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Step 6: Run model calibration for quantization\n",
    "##########################################################################\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "\n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "     \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "     # Enable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.disable_quant()\n",
    "                 module.enable_calib()\n",
    "             else:\n",
    "                 module.disable()\n",
    "\n",
    "     for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "         model(image.cpu())\n",
    "         if i >= num_batches:\n",
    "             break\n",
    "\n",
    "     # Disable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.enable_quant()\n",
    "                 module.disable_calib()\n",
    "             else:\n",
    "                 module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    " # Load calib result\n",
    " for name, module in model.named_modules():\n",
    "     if isinstance(module, quant_nn.TensorQuantizer):\n",
    "         if module._calibrator is not None:\n",
    "             if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                 module.load_calib_amax()\n",
    "             else:\n",
    "                 module.load_calib_amax(**kwargs)\n",
    "         print(F\"{name:40}: {module}\")\n",
    " model.cpu()\n",
    "\n",
    "# It is a bit slow since we collect histograms on CPU\n",
    "with torch.no_grad():\n",
    "    stats = collect_stats(model, data_t, num_batches=2)\n",
    "    amax = compute_amax(model, method=\"percentile\", percentile=99.99)\n",
    "    \n",
    "    # optional - test different calibration methods\n",
    "    #amax = compute_amax(model, method=\"mse\")\n",
    "    #amax = compute_amax(model, method=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46423124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7: Run model evaluation\n",
    "#############################################################################\n",
    "import timeit\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "start_time = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(timeit.default_timer() - start_time)\n",
    "print('Accuracy of the network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9be4fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Step 8: Run approximate-aware re-training\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data_t \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(trainset_1, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                             shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01madapt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreferences\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate, train_one_epoch, load_data\n\u001b[1;32m      8\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "#Step 8: Run approximate-aware re-training\n",
    "#############################################################################\n",
    "data_t = DataLoader(trainset_1, batch_size=512,\n",
    "                                            shuffle=False, num_workers=0)\n",
    "\n",
    "from adapt.references.classification.train import evaluate, train_one_epoch, load_data\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "# finetune the model for one epoch based on data_t subset\n",
    "for i in range(1):\n",
    "    train_one_epoch(model, criterion, optimizer, data_t, \"cpu\", 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9: Rerun model evaluation\n",
    "#############################################################################\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()\n",
    "start_time = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "        images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(timeit.default_timer() - start_time)\n",
    "print('Accuracy of the network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f96bce",
   "metadata": {},
   "source": [
    "100%|██████████| 78/78 [07:10<00:00,  5.52s/it]\n",
    "430.3112167479994\n",
    "Accuracy of the network on the 10000 test images: 67.9487 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
