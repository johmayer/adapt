{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a6f0af6",
   "metadata": {},
   "source": [
    "# Model evaluation and re-training with AdaPT on Imagenet dataset\n",
    "\n",
    "In this notebook you can evaluate different approximate multipliers on various models based on ImageNet dataset\n",
    "\n",
    "Steps:\n",
    "* Select models to load \n",
    "* Select number of threads to use\n",
    "* Choose approximate multiplier \n",
    "* Load model for evaluation\n",
    "* Load dataset\n",
    "* Create validation function\n",
    "* Run model calibration for quantization\n",
    "* Run model evaluation\n",
    "* Run approximate-aware re-training\n",
    "* Rerun model evaluation\n",
    "\n",
    "**Note**:\n",
    "* This notebook should be run on a X86 machine\n",
    "\n",
    "* Please make sure you have run the installation steps first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import torch\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import timeit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b701700",
   "metadata": {},
   "source": [
    "## Select models to load \n",
    "\n",
    "The weights must be downloaded in state_dicts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db2fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.squeezenet_imagenet import squeezenet1_1\n",
    "from models.inception_imagenet import inception_v3\n",
    "from models.shufflenet_imagenet import shufflenet_v2_x1_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ed95a",
   "metadata": {},
   "source": [
    "## Select number of threads to use\n",
    "\n",
    "For optimal performance set them as the number of your cpu threads (not cpu cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 40\n",
    "torch.set_num_threads(threads)\n",
    "\n",
    "#maybe better performance\n",
    "%env OMP_PLACES=cores\n",
    "%env OMP_PROC_BIND=close\n",
    "%env OMP_WAIT_POLICY=active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e86fa02",
   "metadata": {},
   "source": [
    "## Choose approximate multiplier \n",
    "\n",
    "Two approximate multipliers are already provided\n",
    "\n",
    "**mul8s_acc** - (header file: mul8s_acc.h)   <--  default\n",
    "\n",
    "**mul8s_1L2H** - (header file: mul8s_1L2H.h)\n",
    "\n",
    "\n",
    "\n",
    "In order to use your custom multiplier you need to use the provided tool (LUT_generator) to easily create the C++ header for your multiplier. Then you just place it inside the adapt/cpu-kernels/axx_mults folder. The name of the axx_mult here must match the name of the header file. The same axx_mult is used in all layers. \n",
    "\n",
    "Tip: If you want explicitly to set for each layer a different axx_mult you must do it from the model definition using the respective AdaPT_Conv2d class of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "axx_mult = 'mul8s_acc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774d944",
   "metadata": {},
   "source": [
    "## Load model for evaluation\n",
    "\n",
    "Jit compilation method loads 'on the fly' the C++ extentions of the approximate multipliers. Then the pytorch model is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = squeezenet1_1(pretrained=True, axx_mult=axx_mult)\n",
    "model.eval() # for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edbe30f",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Set your path for the ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffe73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valdir = os.path.join('datasets/imagenet_data/val')\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "data = datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    data,\n",
    "    batch_size=64, shuffle=False,\n",
    "    num_workers=0, pin_memory=False)\n",
    "\n",
    "    \n",
    "# sub_val_loader is used for calibration purposes and is a subset of val-dataset\n",
    "# you can set it to point to the train-dataset for more proper re-training\n",
    "evens = list(range(0, len(data), 10))\n",
    "subset = torch.utils.data.Subset(data, evens)\n",
    "sub_val_loader = torch.utils.data.DataLoader(\n",
    "    subset,\n",
    "    batch_size=64, shuffle=False,\n",
    "    num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2487b1b6",
   "metadata": {},
   "source": [
    "## Create validation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, print_freq=100):\n",
    "    with torch.no_grad():\n",
    "        batch_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        top1 = AverageMeter()\n",
    "        top5 = AverageMeter()\n",
    "\n",
    "        # switch to evaluate mode\n",
    "        model.eval()\n",
    "        print(\"starting evaluation...\")\n",
    "\n",
    "        for i, (input, target) in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "            target = target.cpu()\n",
    "            input = input.cpu()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1, prec5 = accuracy(output.data, target.data, topk=(1, 5))\n",
    "            losses.update(loss.data.item(), input.size(0))\n",
    "            top1.update(prec1.item(), input.size(0))\n",
    "            top5.update(prec5.item(), input.size(0))\n",
    "\n",
    "            #print(\"iteration \", print_freq)\n",
    "            if i % print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Acc@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                      'Acc@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                       i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                       top1=top1, top5=top5))\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "        return top1.avg, top5.avg\n",
    "  \n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count  \n",
    " \n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res    \n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55070ba3",
   "metadata": {},
   "source": [
    "## Run model calibration for quantization\n",
    "\n",
    "Calibrates the quantization parameters \n",
    "\n",
    "Need to re-run it each time the model changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "    \n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "     \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "     # Enable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.disable_quant()\n",
    "                 module.enable_calib()\n",
    "             else:\n",
    "                 module.disable()\n",
    "\n",
    "     for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "         model(image.cpu())\n",
    "         if i >= num_batches:\n",
    "             break\n",
    "\n",
    "     # Disable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.enable_quant()\n",
    "                 module.disable_calib()\n",
    "             else:\n",
    "                 module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    " # Load calib result\n",
    " for name, module in model.named_modules():\n",
    "     if isinstance(module, quant_nn.TensorQuantizer):\n",
    "         if module._calibrator is not None:\n",
    "             if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                 module.load_calib_amax()\n",
    "             else:\n",
    "                #use strict=False because inception model throws error\n",
    "                 module.load_calib_amax(strict=False, **kwargs)\n",
    "         print(F\"{name:40}: {module}\")\n",
    " model.cpu()\n",
    "\n",
    "# It is a bit slow since we collect histograms on CPU\n",
    "with torch.no_grad():\n",
    "    stats = collect_stats(model, val_loader, num_batches=2)\n",
    "    amax = compute_amax(model, method=\"percentile\", percentile=99.99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a48a6e",
   "metadata": {},
   "source": [
    "## Run model evaluation\n",
    "\n",
    "Tip: observe how the execution becomes faster and faster with each batch as the CPU achieves better cache re-use on the LUT table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f28db",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(val_loader, model, criterion, print_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e7b94",
   "metadata": {},
   "source": [
    "## Run approximate-aware re-training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt.references.classification.train import evaluate, train_one_epoch, load_data\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "# finetune the model for one epoch based on subset  \n",
    "train_one_epoch(model, criterion, optimizer, sub_val_loader, \"cpu\", 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b72ea",
   "metadata": {},
   "source": [
    "## Rerun model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69f3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate(val_loader, model, criterion, print_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a030dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
